_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_1 (Conv2D)            (None, 128, 28, 28)       2176      
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 128, 28, 28)       262272    
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 128, 14, 14)       0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 128, 14, 14)       0         
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 256, 14, 14)       524544    
_________________________________________________________________
conv2d_4 (Conv2D)            (None, 256, 14, 14)       1048832   
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 256, 7, 7)         0         
_________________________________________________________________
dropout_2 (Dropout)          (None, 256, 7, 7)         0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 12544)             0         
_________________________________________________________________
dense_1 (Dense)              (None, 10)                125450    
=================================================================
Total params: 1,963,274
Trainable params: 1,963,274
Non-trainable params: 0
_________________________________________________________________

* Create a new model. *

Train on 48000 samples, validate on 12000 samples
Epoch 1/30
48000/48000 [==============================] - 137s - loss: 0.4506 - acc: 0.8391 - val_loss: 0.3161 - val_acc: 0.8878
Epoch 2/30
48000/48000 [==============================] - 135s - loss: 0.3140 - acc: 0.8870 - val_loss: 0.2919 - val_acc: 0.8883
Epoch 3/30
48000/48000 [==============================] - 135s - loss: 0.2843 - acc: 0.8970 - val_loss: 0.2573 - val_acc: 0.9067
Epoch 4/30
48000/48000 [==============================] - 135s - loss: 0.2663 - acc: 0.9044 - val_loss: 0.2403 - val_acc: 0.9105
Epoch 5/30
48000/48000 [==============================] - 134s - loss: 0.2569 - acc: 0.9061 - val_loss: 0.2857 - val_acc: 0.8956
Epoch 6/30
48000/48000 [==============================] - 134s - loss: 0.2575 - acc: 0.9068 - val_loss: 0.2413 - val_acc: 0.9098
Epoch 7/30
48000/48000 [==============================] - 134s - loss: 0.2497 - acc: 0.9095 - val_loss: 0.2344 - val_acc: 0.9163
Epoch 8/30
48000/48000 [==============================] - 134s - loss: 0.2399 - acc: 0.9129 - val_loss: 0.2332 - val_acc: 0.9135
Epoch 9/30
48000/48000 [==============================] - 134s - loss: 0.2402 - acc: 0.9121 - val_loss: 0.2303 - val_acc: 0.9189
Epoch 10/30
48000/48000 [==============================] - 134s - loss: 0.2351 - acc: 0.9161 - val_loss: 0.2333 - val_acc: 0.9134
Epoch 11/30
48000/48000 [==============================] - 134s - loss: 0.2306 - acc: 0.9158 - val_loss: 0.2380 - val_acc: 0.9137
Epoch 12/30
48000/48000 [==============================] - 134s - loss: 0.2391 - acc: 0.9149 - val_loss: 0.2361 - val_acc: 0.9173
Epoch 13/30
48000/48000 [==============================] - 134s - loss: 0.2366 - acc: 0.9144 - val_loss: 0.2230 - val_acc: 0.9213
Epoch 14/30
48000/48000 [==============================] - 134s - loss: 0.2365 - acc: 0.9151 - val_loss: 0.2565 - val_acc: 0.9153
Epoch 15/30
48000/48000 [==============================] - 134s - loss: 0.2304 - acc: 0.9174 - val_loss: 0.2389 - val_acc: 0.9163
Epoch 16/30
48000/48000 [==============================] - 134s - loss: 0.2359 - acc: 0.9137 - val_loss: 0.2377 - val_acc: 0.9140
Epoch 17/30
48000/48000 [==============================] - 133s - loss: 0.2268 - acc: 0.9184 - val_loss: 0.2268 - val_acc: 0.9192
Epoch 18/30
48000/48000 [==============================] - 133s - loss: 0.2260 - acc: 0.9183 - val_loss: 0.2329 - val_acc: 0.9147
Epoch 19/30
48000/48000 [==============================] - 133s - loss: 0.2219 - acc: 0.9205 - val_loss: 0.2363 - val_acc: 0.9173
Epoch 20/30
48000/48000 [==============================] - 133s - loss: 0.2237 - acc: 0.9186 - val_loss: 0.2527 - val_acc: 0.9167
Epoch 21/30
48000/48000 [==============================] - 133s - loss: 0.2225 - acc: 0.9202 - val_loss: 0.2440 - val_acc: 0.9147
Epoch 22/30
48000/48000 [==============================] - 133s - loss: 0.2217 - acc: 0.9201 - val_loss: 0.2493 - val_acc: 0.9147
Epoch 23/30
48000/48000 [==============================] - 133s - loss: 0.2280 - acc: 0.9180 - val_loss: 0.2402 - val_acc: 0.9193
Epoch 24/30
48000/48000 [==============================] - 133s - loss: 0.2215 - acc: 0.9192 - val_loss: 0.2458 - val_acc: 0.9162
Epoch 25/30
48000/48000 [==============================] - 133s - loss: 0.2230 - acc: 0.9198 - val_loss: 0.2643 - val_acc: 0.9177
Epoch 26/30
48000/48000 [==============================] - 133s - loss: 0.2220 - acc: 0.9211 - val_loss: 0.2478 - val_acc: 0.9113
Epoch 27/30
48000/48000 [==============================] - 133s - loss: 0.2184 - acc: 0.9212 - val_loss: 0.2356 - val_acc: 0.9173
Epoch 28/30
48000/48000 [==============================] - 133s - loss: 0.2231 - acc: 0.9184 - val_loss: 0.2461 - val_acc: 0.9134
Epoch 29/30
48000/48000 [==============================] - 133s - loss: 0.2242 - acc: 0.9195 - val_loss: 0.2526 - val_acc: 0.9201
Epoch 30/30
48000/48000 [==============================] - 133s - loss: 0.2208 - acc: 0.9204 - val_loss: 0.2478 - val_acc: 0.9139
