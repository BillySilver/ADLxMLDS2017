_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_1 (Conv2D)            (None, 128, 28, 28)       2176      
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 128, 14, 14)       0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 128, 14, 14)       0         
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 256, 14, 14)       524544    
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 256, 7, 7)         0         
_________________________________________________________________
dropout_2 (Dropout)          (None, 256, 7, 7)         0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 12544)             0         
_________________________________________________________________
dense_1 (Dense)              (None, 256)               3211520   
_________________________________________________________________
dropout_3 (Dropout)          (None, 256)               0         
_________________________________________________________________
dense_2 (Dense)              (None, 10)                2570      
=================================================================
Total params: 3,740,810
Trainable params: 3,740,810
Non-trainable params: 0
_________________________________________________________________

* Create a new model. *

Train on 48000 samples, validate on 12000 samples
Epoch 1/30
48000/48000 [==============================] - 59s - loss: 0.4828 - acc: 0.8271 - val_loss: 0.3205 - val_acc: 0.8828
Epoch 2/30
48000/48000 [==============================] - 58s - loss: 0.3556 - acc: 0.8711 - val_loss: 0.2835 - val_acc: 0.8937
Epoch 3/30
48000/48000 [==============================] - 58s - loss: 0.3321 - acc: 0.8773 - val_loss: 0.2684 - val_acc: 0.9013
Epoch 4/30
48000/48000 [==============================] - 58s - loss: 0.3175 - acc: 0.8829 - val_loss: 0.2677 - val_acc: 0.8982
Epoch 5/30
48000/48000 [==============================] - 58s - loss: 0.3078 - acc: 0.8855 - val_loss: 0.2805 - val_acc: 0.8905
Epoch 6/30
48000/48000 [==============================] - 58s - loss: 0.2988 - acc: 0.8895 - val_loss: 0.2536 - val_acc: 0.9041
Epoch 7/30
48000/48000 [==============================] - 58s - loss: 0.2890 - acc: 0.8946 - val_loss: 0.2517 - val_acc: 0.9021
Epoch 8/30
48000/48000 [==============================] - 58s - loss: 0.2923 - acc: 0.8929 - val_loss: 0.2574 - val_acc: 0.9062
Epoch 9/30
48000/48000 [==============================] - 58s - loss: 0.2917 - acc: 0.8952 - val_loss: 0.2480 - val_acc: 0.9084
Epoch 10/30
48000/48000 [==============================] - 58s - loss: 0.2828 - acc: 0.8964 - val_loss: 0.2370 - val_acc: 0.9122
Epoch 11/30
48000/48000 [==============================] - 58s - loss: 0.2822 - acc: 0.8979 - val_loss: 0.2403 - val_acc: 0.9092
Epoch 12/30
48000/48000 [==============================] - 58s - loss: 0.2795 - acc: 0.9001 - val_loss: 0.2431 - val_acc: 0.9102
Epoch 13/30
48000/48000 [==============================] - 58s - loss: 0.2740 - acc: 0.9000 - val_loss: 0.2377 - val_acc: 0.9129
Epoch 14/30
48000/48000 [==============================] - 58s - loss: 0.2737 - acc: 0.8996 - val_loss: 0.2303 - val_acc: 0.9129
Epoch 15/30
48000/48000 [==============================] - 58s - loss: 0.2698 - acc: 0.9006 - val_loss: 0.2234 - val_acc: 0.9189
Epoch 16/30
48000/48000 [==============================] - 58s - loss: 0.2701 - acc: 0.9007 - val_loss: 0.2345 - val_acc: 0.9148
Epoch 17/30
48000/48000 [==============================] - 58s - loss: 0.2671 - acc: 0.9046 - val_loss: 0.2608 - val_acc: 0.9046
Epoch 18/30
48000/48000 [==============================] - 58s - loss: 0.2653 - acc: 0.9028 - val_loss: 0.2358 - val_acc: 0.9145
Epoch 19/30
48000/48000 [==============================] - 58s - loss: 0.2651 - acc: 0.9042 - val_loss: 0.2351 - val_acc: 0.9153
Epoch 20/30
48000/48000 [==============================] - 58s - loss: 0.2657 - acc: 0.9054 - val_loss: 0.2579 - val_acc: 0.9012
Epoch 21/30
48000/48000 [==============================] - 58s - loss: 0.2689 - acc: 0.9017 - val_loss: 0.2359 - val_acc: 0.9142
Epoch 22/30
48000/48000 [==============================] - 58s - loss: 0.2634 - acc: 0.9064 - val_loss: 0.2290 - val_acc: 0.9181
Epoch 23/30
48000/48000 [==============================] - 58s - loss: 0.2652 - acc: 0.9034 - val_loss: 0.2446 - val_acc: 0.9131
Epoch 24/30
48000/48000 [==============================] - 58s - loss: 0.2639 - acc: 0.9042 - val_loss: 0.2417 - val_acc: 0.9123
Epoch 25/30
48000/48000 [==============================] - 58s - loss: 0.2673 - acc: 0.9043 - val_loss: 0.2275 - val_acc: 0.9197
Epoch 26/30
48000/48000 [==============================] - 58s - loss: 0.2616 - acc: 0.9061 - val_loss: 0.2293 - val_acc: 0.9127
Epoch 27/30
48000/48000 [==============================] - 58s - loss: 0.2601 - acc: 0.9066 - val_loss: 0.2620 - val_acc: 0.9006
Epoch 28/30
48000/48000 [==============================] - 58s - loss: 0.2593 - acc: 0.9077 - val_loss: 0.2419 - val_acc: 0.9133
Epoch 29/30
48000/48000 [==============================] - 58s - loss: 0.2654 - acc: 0.9055 - val_loss: 0.2411 - val_acc: 0.9115
Epoch 30/30
48000/48000 [==============================] - 58s - loss: 0.2618 - acc: 0.9072 - val_loss: 0.2354 - val_acc: 0.9156
