_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_1 (Conv2D)            (None, 128, 28, 28)       2176      
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 128, 14, 14)       0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 128, 14, 14)       0         
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 256, 14, 14)       524544    
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 256, 7, 7)         0         
_________________________________________________________________
dropout_2 (Dropout)          (None, 256, 7, 7)         0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 12544)             0         
_________________________________________________________________
dense_1 (Dense)              (None, 2048)              25692160  
_________________________________________________________________
dropout_3 (Dropout)          (None, 2048)              0         
_________________________________________________________________
dense_2 (Dense)              (None, 10)                20490     
=================================================================
Total params: 26,239,370
Trainable params: 26,239,370
Non-trainable params: 0
_________________________________________________________________

* Create a new model. *

Train on 48000 samples, validate on 12000 samples
Epoch 1/30
48000/48000 [==============================] - 111s - loss: 0.4828 - acc: 0.8251 - val_loss: 0.3441 - val_acc: 0.8776
Epoch 2/30
48000/48000 [==============================] - 109s - loss: 0.3681 - acc: 0.8650 - val_loss: 0.2890 - val_acc: 0.8911
Epoch 3/30
48000/48000 [==============================] - 109s - loss: 0.3412 - acc: 0.8765 - val_loss: 0.2951 - val_acc: 0.8898
Epoch 4/30
48000/48000 [==============================] - 109s - loss: 0.3237 - acc: 0.8816 - val_loss: 0.2805 - val_acc: 0.9008
Epoch 5/30
48000/48000 [==============================] - 109s - loss: 0.3217 - acc: 0.8833 - val_loss: 0.2579 - val_acc: 0.9045
Epoch 6/30
48000/48000 [==============================] - 109s - loss: 0.3099 - acc: 0.8870 - val_loss: 0.2765 - val_acc: 0.8969
Epoch 7/30
48000/48000 [==============================] - 109s - loss: 0.3050 - acc: 0.8898 - val_loss: 0.2743 - val_acc: 0.8992
Epoch 8/30
48000/48000 [==============================] - 109s - loss: 0.3039 - acc: 0.8899 - val_loss: 0.2616 - val_acc: 0.9041
Epoch 9/30
48000/48000 [==============================] - 109s - loss: 0.2996 - acc: 0.8920 - val_loss: 0.2555 - val_acc: 0.9055
Epoch 10/30
48000/48000 [==============================] - 109s - loss: 0.3005 - acc: 0.8909 - val_loss: 0.2589 - val_acc: 0.9048
Epoch 11/30
48000/48000 [==============================] - 109s - loss: 0.2956 - acc: 0.8948 - val_loss: 0.2767 - val_acc: 0.9024
Epoch 12/30
48000/48000 [==============================] - 109s - loss: 0.2938 - acc: 0.8952 - val_loss: 0.2809 - val_acc: 0.9018
Epoch 13/30
48000/48000 [==============================] - 109s - loss: 0.2997 - acc: 0.8920 - val_loss: 0.2650 - val_acc: 0.9042
Epoch 14/30
48000/48000 [==============================] - 109s - loss: 0.2941 - acc: 0.8958 - val_loss: 0.2792 - val_acc: 0.8997
Epoch 15/30
48000/48000 [==============================] - 109s - loss: 0.2982 - acc: 0.8931 - val_loss: 0.2447 - val_acc: 0.9093
Epoch 16/30
48000/48000 [==============================] - 109s - loss: 0.2873 - acc: 0.8973 - val_loss: 0.2638 - val_acc: 0.9079
Epoch 17/30
48000/48000 [==============================] - 109s - loss: 0.2943 - acc: 0.8959 - val_loss: 0.2898 - val_acc: 0.9018
Epoch 18/30
48000/48000 [==============================] - 109s - loss: 0.2915 - acc: 0.8952 - val_loss: 0.2609 - val_acc: 0.9083
Epoch 19/30
48000/48000 [==============================] - 109s - loss: 0.2870 - acc: 0.8962 - val_loss: 0.2736 - val_acc: 0.9077
Epoch 20/30
48000/48000 [==============================] - 109s - loss: 0.2944 - acc: 0.8958 - val_loss: 0.2659 - val_acc: 0.9052
Epoch 21/30
48000/48000 [==============================] - 109s - loss: 0.2848 - acc: 0.8989 - val_loss: 0.2518 - val_acc: 0.9095
Epoch 22/30
48000/48000 [==============================] - 109s - loss: 0.2895 - acc: 0.8973 - val_loss: 0.2947 - val_acc: 0.9046
Epoch 23/30
48000/48000 [==============================] - 109s - loss: 0.2890 - acc: 0.8993 - val_loss: 0.2668 - val_acc: 0.9094
Epoch 24/30
48000/48000 [==============================] - 109s - loss: 0.2946 - acc: 0.8967 - val_loss: 0.2648 - val_acc: 0.9053
Epoch 25/30
48000/48000 [==============================] - 109s - loss: 0.2909 - acc: 0.8962 - val_loss: 0.2655 - val_acc: 0.9055
Epoch 26/30
48000/48000 [==============================] - 109s - loss: 0.2854 - acc: 0.9006 - val_loss: 0.2901 - val_acc: 0.9111
Epoch 27/30
48000/48000 [==============================] - 109s - loss: 0.2864 - acc: 0.9008 - val_loss: 0.2670 - val_acc: 0.9051
Epoch 28/30
48000/48000 [==============================] - 109s - loss: 0.2870 - acc: 0.8983 - val_loss: 0.2522 - val_acc: 0.9101
Epoch 29/30
48000/48000 [==============================] - 109s - loss: 0.2913 - acc: 0.8982 - val_loss: 0.2896 - val_acc: 0.9067
Epoch 30/30
48000/48000 [==============================] - 109s - loss: 0.2926 - acc: 0.9001 - val_loss: 0.3004 - val_acc: 0.8980
