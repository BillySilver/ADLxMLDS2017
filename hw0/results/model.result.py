_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_1 (Conv2D)            (None, 128, 28, 28)       2176      
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 128, 14, 14)       0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 128, 14, 14)       0         
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 128, 14, 14)       262272    
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 128, 7, 7)         0         
_________________________________________________________________
dropout_2 (Dropout)          (None, 128, 7, 7)         0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 6272)              0         
_________________________________________________________________
dense_1 (Dense)              (None, 512)               3211776   
_________________________________________________________________
dropout_3 (Dropout)          (None, 512)               0         
_________________________________________________________________
dense_2 (Dense)              (None, 10)                5130      
=================================================================
Total params: 3,481,354
Trainable params: 3,481,354
Non-trainable params: 0
_________________________________________________________________

* Create a new model. *

Train on 48000 samples, validate on 12000 samples
Epoch 1/30
48000/48000 [==============================] - 47s - loss: 0.4719 - acc: 0.8297 - val_loss: 0.3182 - val_acc: 0.8778
Epoch 2/30
48000/48000 [==============================] - 46s - loss: 0.3532 - acc: 0.8709 - val_loss: 0.2711 - val_acc: 0.8987
Epoch 3/30
48000/48000 [==============================] - 46s - loss: 0.3275 - acc: 0.8798 - val_loss: 0.2806 - val_acc: 0.8953
Epoch 4/30
48000/48000 [==============================] - 46s - loss: 0.3182 - acc: 0.8841 - val_loss: 0.2721 - val_acc: 0.8966
Epoch 5/30
48000/48000 [==============================] - 46s - loss: 0.3059 - acc: 0.8877 - val_loss: 0.2566 - val_acc: 0.9062
Epoch 6/30
48000/48000 [==============================] - 46s - loss: 0.2986 - acc: 0.8922 - val_loss: 0.2515 - val_acc: 0.9071
Epoch 7/30
48000/48000 [==============================] - 46s - loss: 0.2921 - acc: 0.8931 - val_loss: 0.2529 - val_acc: 0.9094
Epoch 8/30
48000/48000 [==============================] - 46s - loss: 0.2910 - acc: 0.8930 - val_loss: 0.2581 - val_acc: 0.9049
Epoch 9/30
48000/48000 [==============================] - 46s - loss: 0.2910 - acc: 0.8923 - val_loss: 0.2587 - val_acc: 0.9070
Epoch 10/30
48000/48000 [==============================] - 46s - loss: 0.2873 - acc: 0.8958 - val_loss: 0.2548 - val_acc: 0.9079
Epoch 11/30
48000/48000 [==============================] - 46s - loss: 0.2814 - acc: 0.8962 - val_loss: 0.2448 - val_acc: 0.9129
Epoch 12/30
48000/48000 [==============================] - 46s - loss: 0.2854 - acc: 0.8955 - val_loss: 0.2444 - val_acc: 0.9094
Epoch 13/30
48000/48000 [==============================] - 46s - loss: 0.2786 - acc: 0.9006 - val_loss: 0.2461 - val_acc: 0.9123
Epoch 14/30
48000/48000 [==============================] - 46s - loss: 0.2803 - acc: 0.8986 - val_loss: 0.2552 - val_acc: 0.9124
Epoch 15/30
48000/48000 [==============================] - 46s - loss: 0.2775 - acc: 0.9000 - val_loss: 0.2506 - val_acc: 0.9111
Epoch 16/30
48000/48000 [==============================] - 46s - loss: 0.2778 - acc: 0.9010 - val_loss: 0.2654 - val_acc: 0.9063
Epoch 17/30
48000/48000 [==============================] - 46s - loss: 0.2750 - acc: 0.9009 - val_loss: 0.2791 - val_acc: 0.9022
Epoch 18/30
48000/48000 [==============================] - 46s - loss: 0.2798 - acc: 0.8998 - val_loss: 0.2821 - val_acc: 0.9012
Epoch 19/30
48000/48000 [==============================] - 46s - loss: 0.2718 - acc: 0.9026 - val_loss: 0.2501 - val_acc: 0.9143
Epoch 20/30
48000/48000 [==============================] - 46s - loss: 0.2710 - acc: 0.9028 - val_loss: 0.2356 - val_acc: 0.9122
Epoch 21/30
48000/48000 [==============================] - 46s - loss: 0.2670 - acc: 0.9044 - val_loss: 0.2397 - val_acc: 0.9133
Epoch 22/30
48000/48000 [==============================] - 46s - loss: 0.2720 - acc: 0.9023 - val_loss: 0.2543 - val_acc: 0.9105
Epoch 23/30
48000/48000 [==============================] - 46s - loss: 0.2721 - acc: 0.9040 - val_loss: 0.2496 - val_acc: 0.9129
Epoch 24/30
48000/48000 [==============================] - 46s - loss: 0.2650 - acc: 0.9038 - val_loss: 0.2461 - val_acc: 0.9100
Epoch 25/30
48000/48000 [==============================] - 46s - loss: 0.2761 - acc: 0.9020 - val_loss: 0.2533 - val_acc: 0.9138
Epoch 26/30
48000/48000 [==============================] - 46s - loss: 0.2742 - acc: 0.9021 - val_loss: 0.2525 - val_acc: 0.9089
Epoch 27/30
48000/48000 [==============================] - 46s - loss: 0.2711 - acc: 0.9037 - val_loss: 0.2446 - val_acc: 0.9154
Epoch 28/30
48000/48000 [==============================] - 46s - loss: 0.2728 - acc: 0.9024 - val_loss: 0.2333 - val_acc: 0.9183
Epoch 29/30
48000/48000 [==============================] - 46s - loss: 0.2691 - acc: 0.9050 - val_loss: 0.2480 - val_acc: 0.9122
Epoch 30/30
48000/48000 [==============================] - 46s - loss: 0.2627 - acc: 0.9066 - val_loss: 0.2625 - val_acc: 0.9094
