_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_1 (Conv2D)            (None, 128, 28, 28)       2176      
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 128, 14, 14)       0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 128, 14, 14)       0         
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 256, 14, 14)       524544    
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 256, 7, 7)         0         
_________________________________________________________________
dropout_2 (Dropout)          (None, 256, 7, 7)         0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 12544)             0         
_________________________________________________________________
dense_1 (Dense)              (None, 512)               6423040   
_________________________________________________________________
dropout_3 (Dropout)          (None, 512)               0         
_________________________________________________________________
dense_2 (Dense)              (None, 10)                5130      
=================================================================
Total params: 6,954,890
Trainable params: 6,954,890
Non-trainable params: 0
_________________________________________________________________

* Create a new model. *

Train on 48000 samples, validate on 12000 samples
Epoch 1/30
48000/48000 [==============================] - 66s - loss: 0.4758 - acc: 0.8295 - val_loss: 0.3106 - val_acc: 0.8865
Epoch 2/30
48000/48000 [==============================] - 65s - loss: 0.3507 - acc: 0.8713 - val_loss: 0.2870 - val_acc: 0.8929
Epoch 3/30
48000/48000 [==============================] - 65s - loss: 0.3278 - acc: 0.8789 - val_loss: 0.2751 - val_acc: 0.8974
Epoch 4/30
48000/48000 [==============================] - 65s - loss: 0.3168 - acc: 0.8829 - val_loss: 0.2754 - val_acc: 0.8972
Epoch 5/30
48000/48000 [==============================] - 65s - loss: 0.3071 - acc: 0.8865 - val_loss: 0.2635 - val_acc: 0.9021
Epoch 6/30
48000/48000 [==============================] - 65s - loss: 0.2976 - acc: 0.8904 - val_loss: 0.2494 - val_acc: 0.9102
Epoch 7/30
48000/48000 [==============================] - 65s - loss: 0.2944 - acc: 0.8930 - val_loss: 0.2548 - val_acc: 0.8992
Epoch 8/30
48000/48000 [==============================] - 65s - loss: 0.2911 - acc: 0.8953 - val_loss: 0.2568 - val_acc: 0.9021
Epoch 9/30
48000/48000 [==============================] - 65s - loss: 0.2907 - acc: 0.8941 - val_loss: 0.2380 - val_acc: 0.9117
Epoch 10/30
48000/48000 [==============================] - 65s - loss: 0.2875 - acc: 0.8953 - val_loss: 0.2560 - val_acc: 0.9087
Epoch 11/30
48000/48000 [==============================] - 65s - loss: 0.2886 - acc: 0.8941 - val_loss: 0.2458 - val_acc: 0.9122
Epoch 12/30
48000/48000 [==============================] - 65s - loss: 0.2793 - acc: 0.8971 - val_loss: 0.2469 - val_acc: 0.9093
Epoch 13/30
48000/48000 [==============================] - 65s - loss: 0.2860 - acc: 0.8964 - val_loss: 0.2507 - val_acc: 0.9099
Epoch 14/30
48000/48000 [==============================] - 65s - loss: 0.2747 - acc: 0.9003 - val_loss: 0.2409 - val_acc: 0.9101
Epoch 15/30
48000/48000 [==============================] - 65s - loss: 0.2777 - acc: 0.8989 - val_loss: 0.2485 - val_acc: 0.9091
Epoch 16/30
48000/48000 [==============================] - 65s - loss: 0.2773 - acc: 0.8989 - val_loss: 0.2550 - val_acc: 0.9056
Epoch 17/30
48000/48000 [==============================] - 65s - loss: 0.2771 - acc: 0.9002 - val_loss: 0.2391 - val_acc: 0.9113
Epoch 18/30
48000/48000 [==============================] - 65s - loss: 0.2756 - acc: 0.9000 - val_loss: 0.2359 - val_acc: 0.9121
Epoch 19/30
48000/48000 [==============================] - 65s - loss: 0.2770 - acc: 0.9012 - val_loss: 0.2473 - val_acc: 0.9106
Epoch 20/30
48000/48000 [==============================] - 65s - loss: 0.2791 - acc: 0.9008 - val_loss: 0.2462 - val_acc: 0.9124
Epoch 21/30
48000/48000 [==============================] - 65s - loss: 0.2725 - acc: 0.9016 - val_loss: 0.2523 - val_acc: 0.9094
Epoch 22/30
48000/48000 [==============================] - 65s - loss: 0.2711 - acc: 0.9033 - val_loss: 0.2488 - val_acc: 0.9088
Epoch 23/30
48000/48000 [==============================] - 65s - loss: 0.2780 - acc: 0.9022 - val_loss: 0.2319 - val_acc: 0.9165
Epoch 24/30
48000/48000 [==============================] - 65s - loss: 0.2742 - acc: 0.9025 - val_loss: 0.2324 - val_acc: 0.9173
Epoch 25/30
48000/48000 [==============================] - 65s - loss: 0.2751 - acc: 0.9018 - val_loss: 0.2464 - val_acc: 0.9149
Epoch 26/30
48000/48000 [==============================] - 65s - loss: 0.2705 - acc: 0.9045 - val_loss: 0.2544 - val_acc: 0.9088
Epoch 27/30
48000/48000 [==============================] - 65s - loss: 0.2719 - acc: 0.9029 - val_loss: 0.2477 - val_acc: 0.9077
Epoch 28/30
48000/48000 [==============================] - 65s - loss: 0.2708 - acc: 0.9049 - val_loss: 0.2567 - val_acc: 0.9105
Epoch 29/30
48000/48000 [==============================] - 65s - loss: 0.2723 - acc: 0.9030 - val_loss: 0.2530 - val_acc: 0.9122
Epoch 30/30
48000/48000 [==============================] - 65s - loss: 0.2700 - acc: 0.9049 - val_loss: 0.2434 - val_acc: 0.9146
