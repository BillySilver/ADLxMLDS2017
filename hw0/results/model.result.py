_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_1 (Conv2D)            (None, 32, 28, 28)        544       
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 32, 28, 28)        16416     
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 32, 14, 14)        0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 32, 14, 14)        0         
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 64, 14, 14)        32832     
_________________________________________________________________
conv2d_4 (Conv2D)            (None, 64, 14, 14)        65600     
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 64, 7, 7)          0         
_________________________________________________________________
dropout_2 (Dropout)          (None, 64, 7, 7)          0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 3136)              0         
_________________________________________________________________
dense_1 (Dense)              (None, 256)               803072    
_________________________________________________________________
dropout_3 (Dropout)          (None, 256)               0         
_________________________________________________________________
dense_2 (Dense)              (None, 10)                2570      
=================================================================
Total params: 921,034
Trainable params: 921,034
Non-trainable params: 0
_________________________________________________________________

* Create a new model. *

Train on 48000 samples, validate on 12000 samples
Epoch 1/30
48000/48000 [==============================] - 45s - loss: 0.4899 - acc: 0.8227 - val_loss: 0.2948 - val_acc: 0.8867
Epoch 2/30
48000/48000 [==============================] - 44s - loss: 0.3457 - acc: 0.8730 - val_loss: 0.2751 - val_acc: 0.8969
Epoch 3/30
48000/48000 [==============================] - 44s - loss: 0.3210 - acc: 0.8823 - val_loss: 0.2757 - val_acc: 0.8962
Epoch 4/30
48000/48000 [==============================] - 44s - loss: 0.3036 - acc: 0.8888 - val_loss: 0.2481 - val_acc: 0.9073
Epoch 5/30
48000/48000 [==============================] - 44s - loss: 0.2995 - acc: 0.8898 - val_loss: 0.2439 - val_acc: 0.9090
Epoch 6/30
48000/48000 [==============================] - 44s - loss: 0.2917 - acc: 0.8940 - val_loss: 0.2528 - val_acc: 0.9062
Epoch 7/30
48000/48000 [==============================] - 44s - loss: 0.2865 - acc: 0.8952 - val_loss: 0.2327 - val_acc: 0.9127
Epoch 8/30
48000/48000 [==============================] - 44s - loss: 0.2862 - acc: 0.8969 - val_loss: 0.2343 - val_acc: 0.9105
Epoch 9/30
48000/48000 [==============================] - 44s - loss: 0.2881 - acc: 0.8958 - val_loss: 0.2339 - val_acc: 0.9137
Epoch 10/30
48000/48000 [==============================] - 44s - loss: 0.2848 - acc: 0.8970 - val_loss: 0.2348 - val_acc: 0.9146
Epoch 11/30
48000/48000 [==============================] - 44s - loss: 0.2839 - acc: 0.8970 - val_loss: 0.2270 - val_acc: 0.9152
Epoch 12/30
48000/48000 [==============================] - 44s - loss: 0.2843 - acc: 0.8975 - val_loss: 0.2411 - val_acc: 0.9110
Epoch 13/30
48000/48000 [==============================] - 44s - loss: 0.2846 - acc: 0.8969 - val_loss: 0.2258 - val_acc: 0.9153
Epoch 14/30
48000/48000 [==============================] - 44s - loss: 0.2778 - acc: 0.8994 - val_loss: 0.2297 - val_acc: 0.9153
Epoch 15/30
48000/48000 [==============================] - 44s - loss: 0.2756 - acc: 0.8992 - val_loss: 0.2355 - val_acc: 0.9145
Epoch 16/30
48000/48000 [==============================] - 44s - loss: 0.2807 - acc: 0.8994 - val_loss: 0.2293 - val_acc: 0.9153
Epoch 17/30
48000/48000 [==============================] - 44s - loss: 0.2779 - acc: 0.8987 - val_loss: 0.2442 - val_acc: 0.9097
Epoch 18/30
48000/48000 [==============================] - 44s - loss: 0.2775 - acc: 0.8991 - val_loss: 0.2295 - val_acc: 0.9153
Epoch 19/30
48000/48000 [==============================] - 44s - loss: 0.2814 - acc: 0.8992 - val_loss: 0.2440 - val_acc: 0.9124
Epoch 20/30
48000/48000 [==============================] - 44s - loss: 0.2728 - acc: 0.9012 - val_loss: 0.2335 - val_acc: 0.9123
Epoch 21/30
48000/48000 [==============================] - 44s - loss: 0.2742 - acc: 0.9023 - val_loss: 0.2323 - val_acc: 0.9149
Epoch 22/30
48000/48000 [==============================] - 44s - loss: 0.2793 - acc: 0.8992 - val_loss: 0.2475 - val_acc: 0.9116
Epoch 23/30
48000/48000 [==============================] - 44s - loss: 0.2794 - acc: 0.8982 - val_loss: 0.2451 - val_acc: 0.9119
Epoch 24/30
48000/48000 [==============================] - 44s - loss: 0.2804 - acc: 0.8983 - val_loss: 0.2348 - val_acc: 0.9170
Epoch 25/30
48000/48000 [==============================] - 44s - loss: 0.2681 - acc: 0.9021 - val_loss: 0.2438 - val_acc: 0.9055
Epoch 26/30
48000/48000 [==============================] - 44s - loss: 0.2752 - acc: 0.9011 - val_loss: 0.2347 - val_acc: 0.9123
Epoch 27/30
48000/48000 [==============================] - 44s - loss: 0.2807 - acc: 0.9006 - val_loss: 0.2381 - val_acc: 0.9132
Epoch 28/30
48000/48000 [==============================] - 44s - loss: 0.2798 - acc: 0.9006 - val_loss: 0.2450 - val_acc: 0.9120
Epoch 29/30
48000/48000 [==============================] - 44s - loss: 0.2794 - acc: 0.8998 - val_loss: 0.2390 - val_acc: 0.9126
Epoch 30/30
48000/48000 [==============================] - 44s - loss: 0.2873 - acc: 0.8990 - val_loss: 0.2290 - val_acc: 0.9137
