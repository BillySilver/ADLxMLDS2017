_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_1 (Conv2D)            (None, 64, 28, 28)        1088      
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 64, 28, 28)        65600     
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 64, 14, 14)        0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 64, 14, 14)        0         
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 128, 14, 14)       131200    
_________________________________________________________________
conv2d_4 (Conv2D)            (None, 128, 14, 14)       262272    
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 128, 7, 7)         0         
_________________________________________________________________
dropout_2 (Dropout)          (None, 128, 7, 7)         0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 6272)              0         
_________________________________________________________________
dense_1 (Dense)              (None, 1024)              6423552   
_________________________________________________________________
dropout_3 (Dropout)          (None, 1024)              0         
_________________________________________________________________
dense_2 (Dense)              (None, 10)                10250     
=================================================================
Total params: 6,893,962
Trainable params: 6,893,962
Non-trainable params: 0
_________________________________________________________________

* Create a new model. *

Train on 48000 samples, validate on 12000 samples
Epoch 1/30
48000/48000 [==============================] - 79s - loss: 0.4751 - acc: 0.8283 - val_loss: 0.3078 - val_acc: 0.8852
Epoch 2/30
48000/48000 [==============================] - 78s - loss: 0.3426 - acc: 0.8752 - val_loss: 0.2794 - val_acc: 0.8964
Epoch 3/30
48000/48000 [==============================] - 78s - loss: 0.3198 - acc: 0.8829 - val_loss: 0.2661 - val_acc: 0.9022
Epoch 4/30
48000/48000 [==============================] - 78s - loss: 0.3068 - acc: 0.8887 - val_loss: 0.2549 - val_acc: 0.9038
Epoch 5/30
48000/48000 [==============================] - 78s - loss: 0.3005 - acc: 0.8906 - val_loss: 0.2389 - val_acc: 0.9090
Epoch 6/30
48000/48000 [==============================] - 78s - loss: 0.2977 - acc: 0.8907 - val_loss: 0.2725 - val_acc: 0.8939
Epoch 7/30
48000/48000 [==============================] - 78s - loss: 0.2963 - acc: 0.8916 - val_loss: 0.2891 - val_acc: 0.8937
Epoch 8/30
48000/48000 [==============================] - 78s - loss: 0.2925 - acc: 0.8948 - val_loss: 0.3099 - val_acc: 0.8830
Epoch 9/30
48000/48000 [==============================] - 78s - loss: 0.2857 - acc: 0.8969 - val_loss: 0.2391 - val_acc: 0.9124
Epoch 10/30
48000/48000 [==============================] - 78s - loss: 0.2942 - acc: 0.8948 - val_loss: 0.2828 - val_acc: 0.9000
Epoch 11/30
48000/48000 [==============================] - 78s - loss: 0.2892 - acc: 0.8957 - val_loss: 0.2608 - val_acc: 0.9098
Epoch 12/30
48000/48000 [==============================] - 78s - loss: 0.2882 - acc: 0.8952 - val_loss: 0.2477 - val_acc: 0.9106
Epoch 13/30
48000/48000 [==============================] - 78s - loss: 0.2885 - acc: 0.8950 - val_loss: 0.2397 - val_acc: 0.9097
Epoch 14/30
48000/48000 [==============================] - 78s - loss: 0.2878 - acc: 0.8956 - val_loss: 0.2454 - val_acc: 0.9100
Epoch 15/30
48000/48000 [==============================] - 78s - loss: 0.2918 - acc: 0.8931 - val_loss: 0.2503 - val_acc: 0.9116
Epoch 16/30
48000/48000 [==============================] - 78s - loss: 0.2909 - acc: 0.8953 - val_loss: 0.2844 - val_acc: 0.8964
Epoch 17/30
48000/48000 [==============================] - 78s - loss: 0.2889 - acc: 0.8962 - val_loss: 0.2456 - val_acc: 0.9089
Epoch 18/30
48000/48000 [==============================] - 77s - loss: 0.2904 - acc: 0.8953 - val_loss: 0.2610 - val_acc: 0.9038
Epoch 19/30
48000/48000 [==============================] - 78s - loss: 0.2883 - acc: 0.8965 - val_loss: 0.2842 - val_acc: 0.8962
Epoch 20/30
48000/48000 [==============================] - 78s - loss: 0.2925 - acc: 0.8956 - val_loss: 0.2393 - val_acc: 0.9167
Epoch 21/30
48000/48000 [==============================] - 78s - loss: 0.2918 - acc: 0.8935 - val_loss: 0.2366 - val_acc: 0.9125
Epoch 22/30
48000/48000 [==============================] - 78s - loss: 0.2852 - acc: 0.8981 - val_loss: 0.2541 - val_acc: 0.9061
Epoch 23/30
48000/48000 [==============================] - 78s - loss: 0.2980 - acc: 0.8927 - val_loss: 0.2719 - val_acc: 0.9033
Epoch 24/30
48000/48000 [==============================] - 78s - loss: 0.2911 - acc: 0.8960 - val_loss: 0.2309 - val_acc: 0.9137
Epoch 25/30
48000/48000 [==============================] - 78s - loss: 0.2863 - acc: 0.8980 - val_loss: 0.2364 - val_acc: 0.9159
Epoch 26/30
48000/48000 [==============================] - 78s - loss: 0.2853 - acc: 0.8973 - val_loss: 0.2441 - val_acc: 0.9121
Epoch 27/30
48000/48000 [==============================] - 78s - loss: 0.2898 - acc: 0.8979 - val_loss: 0.2241 - val_acc: 0.9159
Epoch 28/30
48000/48000 [==============================] - 78s - loss: 0.2983 - acc: 0.8933 - val_loss: 0.2547 - val_acc: 0.9068
Epoch 29/30
48000/48000 [==============================] - 78s - loss: 0.2890 - acc: 0.8961 - val_loss: 0.2381 - val_acc: 0.9116
Epoch 30/30
48000/48000 [==============================] - 78s - loss: 0.2972 - acc: 0.8940 - val_loss: 0.2521 - val_acc: 0.9049
