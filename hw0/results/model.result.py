_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_1 (Conv2D)            (None, 128, 28, 28)       2176      
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 128, 14, 14)       0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 128, 14, 14)       0         
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 256, 14, 14)       524544    
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 256, 7, 7)         0         
_________________________________________________________________
dropout_2 (Dropout)          (None, 256, 7, 7)         0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 12544)             0         
_________________________________________________________________
dense_1 (Dense)              (None, 1024)              12846080  
_________________________________________________________________
dropout_3 (Dropout)          (None, 1024)              0         
_________________________________________________________________
dense_2 (Dense)              (None, 10)                10250     
=================================================================
Total params: 13,383,050
Trainable params: 13,383,050
Non-trainable params: 0
_________________________________________________________________

* Create a new model. *

Train on 48000 samples, validate on 12000 samples
Epoch 1/30
48000/48000 [==============================] - 81s - loss: 0.4676 - acc: 0.8297 - val_loss: 0.3160 - val_acc: 0.8789
Epoch 2/30
48000/48000 [==============================] - 80s - loss: 0.3511 - acc: 0.8700 - val_loss: 0.2823 - val_acc: 0.8968
Epoch 3/30
48000/48000 [==============================] - 80s - loss: 0.3300 - acc: 0.8792 - val_loss: 0.2865 - val_acc: 0.8949
Epoch 4/30
48000/48000 [==============================] - 80s - loss: 0.3200 - acc: 0.8845 - val_loss: 0.2717 - val_acc: 0.8971
Epoch 5/30
48000/48000 [==============================] - 79s - loss: 0.3073 - acc: 0.8883 - val_loss: 0.2549 - val_acc: 0.9069
Epoch 6/30
48000/48000 [==============================] - 79s - loss: 0.3002 - acc: 0.8893 - val_loss: 0.2585 - val_acc: 0.9049
Epoch 7/30
48000/48000 [==============================] - 79s - loss: 0.2928 - acc: 0.8926 - val_loss: 0.2837 - val_acc: 0.8925
Epoch 8/30
48000/48000 [==============================] - 79s - loss: 0.2947 - acc: 0.8926 - val_loss: 0.2711 - val_acc: 0.9041
Epoch 9/30
48000/48000 [==============================] - 80s - loss: 0.2861 - acc: 0.8964 - val_loss: 0.2451 - val_acc: 0.9088
Epoch 10/30
48000/48000 [==============================] - 79s - loss: 0.2846 - acc: 0.8965 - val_loss: 0.2480 - val_acc: 0.9099
Epoch 11/30
48000/48000 [==============================] - 79s - loss: 0.2825 - acc: 0.8988 - val_loss: 0.2581 - val_acc: 0.9103
Epoch 12/30
48000/48000 [==============================] - 79s - loss: 0.2906 - acc: 0.8970 - val_loss: 0.2469 - val_acc: 0.9095
Epoch 13/30
48000/48000 [==============================] - 79s - loss: 0.2778 - acc: 0.8992 - val_loss: 0.2558 - val_acc: 0.9055
Epoch 14/30
48000/48000 [==============================] - 79s - loss: 0.2764 - acc: 0.8995 - val_loss: 0.2575 - val_acc: 0.9094
Epoch 15/30
48000/48000 [==============================] - 79s - loss: 0.2755 - acc: 0.8996 - val_loss: 0.2480 - val_acc: 0.9103
Epoch 16/30
48000/48000 [==============================] - 79s - loss: 0.2804 - acc: 0.8995 - val_loss: 0.2581 - val_acc: 0.9084
Epoch 17/30
48000/48000 [==============================] - 79s - loss: 0.2784 - acc: 0.9009 - val_loss: 0.2517 - val_acc: 0.9099
Epoch 18/30
48000/48000 [==============================] - 79s - loss: 0.2735 - acc: 0.9026 - val_loss: 0.2438 - val_acc: 0.9127
Epoch 19/30
48000/48000 [==============================] - 79s - loss: 0.2785 - acc: 0.9003 - val_loss: 0.2654 - val_acc: 0.9134
Epoch 20/30
48000/48000 [==============================] - 79s - loss: 0.2706 - acc: 0.9029 - val_loss: 0.2546 - val_acc: 0.9093
Epoch 21/30
48000/48000 [==============================] - 79s - loss: 0.2747 - acc: 0.9013 - val_loss: 0.2875 - val_acc: 0.9043
Epoch 22/30
48000/48000 [==============================] - 79s - loss: 0.2773 - acc: 0.9003 - val_loss: 0.2483 - val_acc: 0.9118
Epoch 23/30
48000/48000 [==============================] - 79s - loss: 0.2816 - acc: 0.8996 - val_loss: 0.2768 - val_acc: 0.9075
Epoch 24/30
48000/48000 [==============================] - 79s - loss: 0.2747 - acc: 0.9027 - val_loss: 0.2638 - val_acc: 0.9047
Epoch 25/30
48000/48000 [==============================] - 79s - loss: 0.2724 - acc: 0.9035 - val_loss: 0.2483 - val_acc: 0.9110
Epoch 26/30
48000/48000 [==============================] - 79s - loss: 0.2741 - acc: 0.9030 - val_loss: 0.2551 - val_acc: 0.9123
Epoch 27/30
48000/48000 [==============================] - 79s - loss: 0.2744 - acc: 0.9029 - val_loss: 0.2644 - val_acc: 0.9124
Epoch 28/30
48000/48000 [==============================] - 79s - loss: 0.2698 - acc: 0.9030 - val_loss: 0.2624 - val_acc: 0.9087
Epoch 29/30
48000/48000 [==============================] - 79s - loss: 0.2711 - acc: 0.9071 - val_loss: 0.2508 - val_acc: 0.9100
Epoch 30/30
48000/48000 [==============================] - 79s - loss: 0.2737 - acc: 0.9037 - val_loss: 0.2573 - val_acc: 0.9144
