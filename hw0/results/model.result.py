_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_1 (Conv2D)            (None, 64, 28, 28)        1088      
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 64, 28, 28)        65600     
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 64, 14, 14)        0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 64, 14, 14)        0         
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 128, 14, 14)       131200    
_________________________________________________________________
conv2d_4 (Conv2D)            (None, 128, 14, 14)       262272    
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 128, 7, 7)         0         
_________________________________________________________________
dropout_2 (Dropout)          (None, 128, 7, 7)         0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 6272)              0         
_________________________________________________________________
dense_1 (Dense)              (None, 2048)              12847104  
_________________________________________________________________
dropout_3 (Dropout)          (None, 2048)              0         
_________________________________________________________________
dense_2 (Dense)              (None, 10)                20490     
=================================================================
Total params: 13,327,754
Trainable params: 13,327,754
Non-trainable params: 0
_________________________________________________________________

* Create a new model. *

Train on 48000 samples, validate on 12000 samples
Epoch 1/30
48000/48000 [==============================] - 94s - loss: 0.4930 - acc: 0.8207 - val_loss: 0.3213 - val_acc: 0.8811
Epoch 2/30
48000/48000 [==============================] - 92s - loss: 0.3592 - acc: 0.8691 - val_loss: 0.2867 - val_acc: 0.8948
Epoch 3/30
48000/48000 [==============================] - 92s - loss: 0.3262 - acc: 0.8806 - val_loss: 0.2775 - val_acc: 0.9011
Epoch 4/30
48000/48000 [==============================] - 92s - loss: 0.3139 - acc: 0.8848 - val_loss: 0.2672 - val_acc: 0.9027
Epoch 5/30
48000/48000 [==============================] - 92s - loss: 0.3108 - acc: 0.8862 - val_loss: 0.2590 - val_acc: 0.9036
Epoch 6/30
48000/48000 [==============================] - 92s - loss: 0.3045 - acc: 0.8886 - val_loss: 0.2712 - val_acc: 0.9058
Epoch 7/30
48000/48000 [==============================] - 92s - loss: 0.3014 - acc: 0.8899 - val_loss: 0.2419 - val_acc: 0.9093
Epoch 8/30
48000/48000 [==============================] - 92s - loss: 0.3000 - acc: 0.8926 - val_loss: 0.2428 - val_acc: 0.9103
Epoch 9/30
48000/48000 [==============================] - 92s - loss: 0.2993 - acc: 0.8921 - val_loss: 0.2319 - val_acc: 0.9126
Epoch 10/30
48000/48000 [==============================] - 92s - loss: 0.2991 - acc: 0.8918 - val_loss: 0.2510 - val_acc: 0.9087
Epoch 11/30
48000/48000 [==============================] - 92s - loss: 0.2968 - acc: 0.8927 - val_loss: 0.2579 - val_acc: 0.9047
Epoch 12/30
48000/48000 [==============================] - 93s - loss: 0.2927 - acc: 0.8935 - val_loss: 0.2410 - val_acc: 0.9110
Epoch 13/30
48000/48000 [==============================] - 92s - loss: 0.2997 - acc: 0.8942 - val_loss: 0.2434 - val_acc: 0.9100
Epoch 14/30
48000/48000 [==============================] - 92s - loss: 0.2982 - acc: 0.8937 - val_loss: 0.2372 - val_acc: 0.9128
Epoch 15/30
48000/48000 [==============================] - 92s - loss: 0.3061 - acc: 0.8914 - val_loss: 0.2661 - val_acc: 0.9033
Epoch 16/30
48000/48000 [==============================] - 92s - loss: 0.2972 - acc: 0.8923 - val_loss: 0.2419 - val_acc: 0.9083
Epoch 17/30
48000/48000 [==============================] - 92s - loss: 0.2894 - acc: 0.8970 - val_loss: 0.2380 - val_acc: 0.9116
Epoch 18/30
48000/48000 [==============================] - 92s - loss: 0.2967 - acc: 0.8936 - val_loss: 0.2447 - val_acc: 0.9102
Epoch 19/30
48000/48000 [==============================] - 92s - loss: 0.2958 - acc: 0.8936 - val_loss: 0.2568 - val_acc: 0.9073
Epoch 20/30
48000/48000 [==============================] - 92s - loss: 0.3024 - acc: 0.8911 - val_loss: 0.2440 - val_acc: 0.9113
Epoch 21/30
48000/48000 [==============================] - 92s - loss: 0.2993 - acc: 0.8917 - val_loss: 0.2334 - val_acc: 0.9137
Epoch 22/30
48000/48000 [==============================] - 92s - loss: 0.2939 - acc: 0.8947 - val_loss: 0.2506 - val_acc: 0.9072
Epoch 23/30
48000/48000 [==============================] - 92s - loss: 0.2993 - acc: 0.8919 - val_loss: 0.2396 - val_acc: 0.9125
Epoch 24/30
48000/48000 [==============================] - 92s - loss: 0.3009 - acc: 0.8925 - val_loss: 0.2716 - val_acc: 0.8998
Epoch 25/30
48000/48000 [==============================] - 92s - loss: 0.3003 - acc: 0.8905 - val_loss: 0.2450 - val_acc: 0.9082
Epoch 26/30
48000/48000 [==============================] - 92s - loss: 0.2985 - acc: 0.8935 - val_loss: 0.2747 - val_acc: 0.9019
Epoch 27/30
48000/48000 [==============================] - 92s - loss: 0.2891 - acc: 0.8960 - val_loss: 0.2450 - val_acc: 0.9132
Epoch 28/30
48000/48000 [==============================] - 92s - loss: 0.3032 - acc: 0.8917 - val_loss: 0.2390 - val_acc: 0.9151
Epoch 29/30
48000/48000 [==============================] - 92s - loss: 0.2971 - acc: 0.8937 - val_loss: 0.2574 - val_acc: 0.9079
Epoch 30/30
48000/48000 [==============================] - 92s - loss: 0.2986 - acc: 0.8925 - val_loss: 0.2557 - val_acc: 0.9085
